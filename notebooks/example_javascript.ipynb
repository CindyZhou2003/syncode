{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.getcwd() + '/../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amazinguknow/Documents/code/syncode/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from syncode import Syncode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_name = \"microsoft/phi-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-19 22:43:47,751-root] - Loading model microsoft/phi-2 with device:cuda, device_map:auto, torch_dtype:torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-19 22:43:58,588-accelerate.big_modeling] - Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output:\n",
      " to the console.\n",
      "\n",
      "```javascript\n",
      "// HelloWorld.js\n",
      "\n",
      "console.log(\"Hello World!\");\n",
      "```\n",
      "\n",
      "Exercise 2:\n",
      "Create a new directory called \"my_app\" and navigate to it in your terminal.\n",
      "\n",
      "```bash\n",
      "mkdir my_app\n",
      "cd my_app\n",
      "```\n",
      "\n",
      "Exercise 3:\n",
      "Create a new file called \"app.js\" in the \"my_app\" directory.\n",
      "\n",
      "```bash\n",
      "touch app.js\n",
      "```\n",
      "\n",
      "Exercise 4:\n",
      "Add the following code to the \"app.js\" file:\n",
      "\n",
      "```javascript\n",
      "console.log(\"Hello, my_app!\");\n",
      "```\n",
      "\n",
      "Exercise 5:\n",
      "Create a new file called \"main.js\" in the \"my_app\" directory.\n",
      "\n",
      "```bash\n",
      "touch main.js\n",
      "```\n",
      "\n",
      "Exercise 6:\n",
      "Add the following code to the \"main.js\" file:\n",
      "\n",
      "```javascript\n",
      "import \"app.js\";\n",
      "\n",
      "app.log(\"Hello, my_app!\");\n",
      "```\n",
      "\n",
      "Exercise 7:\n",
      "Run the \"main.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the unconstrained original model\n",
    "llm = Syncode(model = model_name, mode='original', max_new_tokens=250)\n",
    "\n",
    "prompt = \"Write HelloWorld.js, which prints Hello World!\"\n",
    "output = llm.infer(prompt)[0]\n",
    "print(f\"LLM output:\\n{output}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard LLM answer also includes a text part `A: You can use the following code:`. This text could be different everytime and hence it is difficult to extract the answer from the text. \n",
    "\n",
    "In addition, the LLM repeatedly outputs the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-19 23:27:18,063-root] - Loading model microsoft/phi-2 with device:cuda, device_map:auto, torch_dtype:torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-19 23:27:50,830-accelerate.big_modeling] - Some parameters are on the meta device because they were offloaded to the disk.\n",
      "[2025-12-19 23:27:51,609-syncode.mask_store.mask_store] - Using cache: True and fsm path cache/mask_stores/CodeGenTokenizerFast/grammar_mask_8081383952_50257.pkl exist: False\n",
      "[2025-12-19 23:27:51,609-syncode.mask_store.mask_store] - Creating mask store for CodeGenTokenizerFast and javascript, may take more than 10 minutes. Caching at /Users/amazinguknow/Documents/code/syncode/notebooks/cache/mask_stores/CodeGenTokenizerFast/grammar_mask_8081383952_50257.pkl.\n",
      "[2025-12-19 23:27:51,964-syncode.mask_store.fsm_set] - 109 FSMs with 477 states initialized in 0.01 seconds\n",
      "[2025-12-19 23:27:51,964-syncode.mask_store.mask_store] - Ignore whitespace is True\n",
      "[2025-12-19 23:27:51,974-syncode.mask_store.mask_store] - Number of 2 length terminal sequences reduced from 11881 to 3948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [02:11<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-19 23:30:08,040-syncode.mask_store.mask_store] - Time taken to create mask store: 136.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Load the Syncode augmented model\n",
    "syn_llm_output = Syncode(model = model_name, mode='grammar_mask', grammar='javascript', parse_output_only=True)\n",
    "prompt = \"Write HelloWorld.js, which prints Hello World!\"\n",
    "\n",
    "output = syn_llm_output.infer(prompt)[0]\n",
    "print(f\"Syncode augmented LLM output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SynCode solves this problem and the output is purely a single instance of the correct code!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
